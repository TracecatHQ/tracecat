name: Integration Tests

on:
  push:
    branches: ["main"]
    paths:
      - tracecat/**
      - registry/**
      - tests/integration/**
      - pyproject.toml
      - uv.lock
      - Dockerfile
      - docker-compose.yml
      - docker-compose.dev.yml
      - docker-compose.local.yml
      - .github/workflows/run-integration-tests.yml
  pull_request:
    branches: ["main", "staging"]
    paths:
      - tracecat/**
      - registry/**
      - tests/integration/**
      - pyproject.toml
      - uv.lock
      - Dockerfile
      - docker-compose.yml
      - docker-compose.dev.yml
      - docker-compose.local.yml
      - .github/workflows/run-integration-tests.yml
  workflow_dispatch:
    inputs:
      git-ref:
        description: "Git Ref (Optional)"
        required: false

permissions:
  contents: read
  packages: write

jobs:
  # ──────────────────────────────────────────────────────────────────
  # 1.  LIGHTWEIGHT SSH / INSTALL SMOKE-TEST
  # ──────────────────────────────────────────────────────────────────
  ssh-sanity:
    runs-on: ubuntu-latest
    timeout-minutes: 5 # short fail-fast window
    steps:
      - uses: actions/checkout@v4

      # Load the private deploy key into an ssh-agent.
      # The secret value MUST be the *raw* PEM text, not base64.
      - uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.CUSTOM_REPO_SSH_PRIVATE_KEY }}

      - name: Install uv
        uses: useblacksmith/setup-uv@v4
        with:
          version: "0.9.7"

      - name: Set up Python 3.12
        uses: useblacksmith/setup-python@v6
        with:
          python-version: "3.12"

      # Lightweight connectivity check — choose ONE:
      #
      # A) Strict git connectivity (fastest, no deps):
      - name: Verify git over SSH
        run: git ls-remote git@github.com:TracecatHQ/internal-registry.git HEAD
      #
      # B) End-to-end install smoke-test (still <10 s):
      #- name: Smoke-test pip install via SSH
      #  run: |
      #    uv pip install --no-deps --quiet \
      #      "git+ssh://git@github.com/TracecatHQ/internal-registry.git@main"
      #    python -c "import importlib, sys; print('import ok:', bool(importlib.import_module('internal_registry', package=None))); sys.exit(0)"

  # ──────────────────────────────────────────────────────────────────
  # 2.  FULL INTEGRATION TESTS (with pytest-xdist for parallelization)
  #     Uses worker-specific task queues from conftest.py for isolation
  # ──────────────────────────────────────────────────────────────────
  test-integration:
    needs: ssh-sanity # only start if key check passed
    runs-on: blacksmith-4vcpu-ubuntu-2204
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.git-ref }}

      - name: Install uv
        uses: useblacksmith/setup-uv@v4
        with:
          version: "0.9.7"
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Set up Python 3.12
        uses: useblacksmith/setup-python@v6
        with:
          python-version: "3.12"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Run environment setup script
        run: |
          echo "y
          localhost
          n
          test@tracecat.com" | bash env.sh

      - name: Start core Docker services
        env:
          COMPOSE_BAKE: "true"
          TRACECAT__UNSAFE_DISABLE_SM_MASKING: "true"
          TRACECAT__EXECUTOR_BACKEND: "direct"
          TRACECAT__FEATURE_FLAGS: "registry-sync-v2,registry-client"
          # Disable sandboxed registry sync to use local subprocess instead of Temporal workflow
          # This avoids the need for Docker executor to handle RegistrySyncWorkflow
          TRACECAT__REGISTRY_SYNC_SANDBOX_ENABLED: "false"
        run: |
          docker compose -f docker-compose.local.yml up -d temporal api worker executor postgres_db caddy minio redis

          # Wait for services with health checks to become healthy
          echo "Waiting for services to become healthy..."
          timeout 300 bash -c '
            while true; do
              # Get health status of all services, filter to those with health checks
              # A service is ready when Health is exactly "healthy" (not empty, null, or starting)
              # Note: docker compose ps --format json outputs JSON Lines (one object per line),
              # so we use jq -s to slurp them into an array first
              statuses=$(docker compose -f docker-compose.local.yml ps --format json | jq -s -r ".[] | select(.Health != null and .Health != \"\") | .Health")

              # Count healthy vs total services with health checks
              total=$(echo "$statuses" | grep -c . || true)
              healthy=$(echo "$statuses" | grep -c "^healthy$" || true)

              if [ "$total" -eq 0 ]; then
                echo "No services with health checks found yet, waiting..."
                sleep 5
              elif [ "$healthy" -lt "$total" ]; then
                echo "Waiting for services to be healthy ($healthy/$total ready)..."
                sleep 5
              else
                echo "All $total services with health checks are healthy"
                break
              fi
            done
          '

          # Show final service status
          docker compose -f docker-compose.local.yml ps

          # Verify postgres is accessible from host (core-db network is not internal)
          echo "Verifying PostgreSQL is accessible from host..."
          timeout 30 bash -c 'until pg_isready -h localhost -p 5432 -U postgres; do sleep 1; done'
          echo "PostgreSQL is ready"

      - name: Run integration tests
        env:
          # Expect a base64 encoded key
          CUSTOM_REPO_SSH_PRIVATE_KEY: ${{ secrets.CUSTOM_REPO_SSH_PRIVATE_KEY }}
          # Use local subprocess sync instead of Temporal workflow (faster, simpler for CI)
          TRACECAT__REGISTRY_SYNC_SANDBOX_ENABLED: "false"
          TRACECAT__DISABLE_NSJAIL: "true"
        run: |
          # Run pool tests sequentially (subprocess spawning doesn't parallelize well)
          uv run pytest tests/integration/test_pool_integration.py -ra -v -o faulthandler_timeout=300

          # Run other integration tests in parallel with pytest-xdist
          # Worker-specific task queues in conftest.py ensure isolation
          uv run pytest tests/integration --ignore=tests/integration/test_pool_integration.py -n auto -ra -v -o faulthandler_timeout=300

      - name: Show Docker logs on failure
        if: failure()
        run: |
          echo "=== Docker Service Status ==="
          docker compose -f docker-compose.local.yml ps

          echo "=== API Logs ==="
          docker compose -f docker-compose.local.yml logs api --tail=200

          echo "=== Worker Logs ==="
          docker compose -f docker-compose.local.yml logs worker --tail=200

          echo "=== Executor Logs ==="
          docker compose -f docker-compose.local.yml logs executor --tail=200

          echo "=== Temporal Logs ==="
          docker compose -f docker-compose.local.yml logs temporal --tail=200

          echo "=== Redis Logs ==="
          docker compose -f docker-compose.local.yml logs redis --tail=200

          echo "=== MinIO Logs ==="
          docker compose -f docker-compose.local.yml logs minio --tail=200

          echo "=== PostgreSQL Logs ==="
          docker compose -f docker-compose.local.yml logs postgres_db --tail=200

      - name: Clean up
        if: always()
        run: |
          docker compose -f docker-compose.local.yml down -v
