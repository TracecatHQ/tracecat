# LiteLLM Proxy Configuration
# Credentials are NOT stored here - they're injected per-request via custom_auth

model_list:
  # OpenAI models
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini

  - model_name: gpt-5-mini
    litellm_params:
      model: openai/gpt-5-mini

  - model_name: gpt-5-nano
    litellm_params:
      model: openai/gpt-5-nano

  - model_name: gpt-5
    litellm_params:
      model: openai/gpt-5

  # Anthropic models
  - model_name: claude-sonnet-4-5-20250929
    litellm_params:
      model: anthropic/claude-sonnet-4-5-20250929

  - model_name: claude-haiku-4-5-20251001
    litellm_params:
      model: anthropic/claude-haiku-4-5-20251001

  - model_name: claude-opus-4-5-20251101
    litellm_params:
      model: anthropic/claude-opus-4-5-20251101

  # Bedrock (model ARN injected from credentials)
  - model_name: bedrock
    litellm_params:
      model: bedrock/placeholder

  # Custom model provider (base_url, model injected from credentials)
  - model_name: custom
    litellm_params:
      model: openai/placeholder

general_settings:
  custom_auth: tracecat.llm_gateway.custom_auth.user_api_key_auth
  database_url: null

litellm_settings:
  callbacks: tracecat.llm_gateway.custom_auth
  drop_params: true
